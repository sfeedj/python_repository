{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "library(Amelia)\n",
    "library(cattonum)\n",
    "library(tidyverse)\n",
    "library(leaps)\n",
    "library(MASS)\n",
    "library(pROC)\n",
    "library(e1071)\n",
    "library(rpart.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file <- read.csv(\"orange_churn_test.csv\",na.strings=c(\"\"))\n",
    "data_train <- read.csv(\"orange_churn_train.csv\",na.strings=c(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Afficher un graph avec les valeurs manquantes vs les valeurs observÃ©es\n",
    "# missmap(data_train, main = \"Missing values vs observed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline <- function(dataframe){\n",
    "    #remove columns that are 90% empty\n",
    "    p_data<- dataframe[,colSums(is.na(dataframe))<9000]\n",
    "    \n",
    "    #replace NA by mean for integers and doubles\n",
    "    for(col in names(p_data)){\n",
    "        if( typeof(p_data[[col]]) == \"integer\" | typeof(p_data[[col]]) == \"double\"){\n",
    "            p_data[[col]]= ifelse(is.na(p_data[[col]]), ave(p_data[[col]], FUN = function(x) mean(x, na.rm = 'TRUE')), p_data[[col]])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    #replace NA in string cols by \"Missing\"\n",
    "    p_data[is.na(p_data)] <- \"Missing\"\n",
    "    \n",
    "    #frequency encoding\n",
    "    p_data = catto_freq(p_data, verbose=TRUE)\n",
    "                                                                      \n",
    "    #remove columns with no variance\n",
    "    p_data<-p_data[c(TRUE, lapply(p_data[-1], var, na.rm = TRUE) != 0)]\n",
    "\n",
    "    return(p_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data_train <- processing_pipeline(data_train)\n",
    "p_data_train$churn <- ifelse(p_data_train$churn==1,'yes','no')\n",
    "labels <- as.factor(p_data_train$churn)\n",
    "p_data_train$churn <- NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor <- cor(p_data_train)\n",
    "hc <- findCorrelation(cor, cutoff=0.9)\n",
    "# paste(hc,collapse=\", \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cor <- function(dataset){\n",
    "    hc <- c(2, 3, 4, 5, 6, 7, 9, 10, 12, 14, 15, 16, 17, 18, 20, 21, 24, 25, 27, 28, 30, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 66, 68, 70, 71, 72, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 87, 89, 90, 91, 93, 94, 96, 97, 98, 100, 101, 104, 105, 106, 107, 109, 110, 111, 112, 114, 117, 119, 120, 121, 123, 125, 126, 127, 129, 131, 134, 135, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 173, 182, 184, 185, 191, 196, 201, 207)\n",
    "    reduced_data_train = dataset[,-c(hc)]\n",
    "    return(reduced_data_train)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_train <- remove_cor(p_data_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data_train$churn = labels\n",
    "splitIndex <- createDataPartition(reduced_data_train$churn, p = .5, list = FALSE, times = 1)\n",
    "trainDF <- reduced_data_train[ splitIndex,]\n",
    "testDF  <- reduced_data_train[-splitIndex,]\n",
    "\n",
    "outcomeName <- 'churn'\n",
    "predictorsNames <- names(trainDF)[names(trainDF) != outcomeName]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMclassifier = svm(formula = churn ~ .,\n",
    "                 data = trainDF,\n",
    "                 type = 'C-classification',\n",
    "                 kernel = 'linear') #can be tweaked : https://www.rdocumentation.org/packages/e1071/versions/1.7-4/topics/svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(SVMclassifier, newdata = testDF)\n",
    "train_pred = predict(SVMclassifier, newdata = trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = table(testDF$churn, pred)\n",
    "cm2 = table(trainDF$churn, train_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  no  yes \n",
       "4632  368 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(trainDF$churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "objControl <- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)\n",
    "set.seed(3333)\n",
    "dtree_fit <- train(churn ~., data = trainDF, method = \"rpart\",\n",
    "                   parms = list(split = \"information\"),\n",
    "                   trControl=objControl,\n",
    "                   tuneLength = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "5000 samples\n",
       "  78 predictor\n",
       "   2 classes: 'no', 'yes' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
       "Summary of sample sizes: 4501, 4500, 4500, 4500, 4500, 4500, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  cp            Accuracy   Kappa     \n",
       "  0.0000000000  0.8956008  0.08256762\n",
       "  0.0007548309  0.9004007  0.08894846\n",
       "  0.0015096618  0.9059339  0.09053515\n",
       "  0.0022644928  0.9134666  0.09813855\n",
       "  0.0030193237  0.9174686  0.08961233\n",
       "  0.0037741546  0.9204676  0.07570664\n",
       "  0.0045289855  0.9222004  0.06439860\n",
       "  0.0052838164  0.9251999  0.06075149\n",
       "  0.0060386473  0.9252001  0.05066131\n",
       "  0.0067934783  0.9254002  0.02466325\n",
       "\n",
       "Accuracy was used to select the optimal model using the largest value.\n",
       "The final value used for the model was cp = 0.006793478."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dtree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(dtree_fit, newdata = testDF)\n",
    "train_pred = predict(dtree_fit, newdata = trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = table(testDF$churn, pred)\n",
    "cm2 = table(trainDF$churn, train_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -. GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5243             nan     0.1000    0.0004\n",
      "     2        0.5225             nan     0.1000    0.0001\n",
      "     3        0.5197             nan     0.1000    0.0001\n",
      "     4        0.5186             nan     0.1000    0.0002\n",
      "     5        0.5156             nan     0.1000    0.0013\n",
      "     6        0.5150             nan     0.1000   -0.0000\n",
      "     7        0.5127             nan     0.1000    0.0009\n",
      "     8        0.5107             nan     0.1000   -0.0001\n",
      "     9        0.5097             nan     0.1000   -0.0006\n",
      "    10        0.5085             nan     0.1000    0.0001\n",
      "    20        0.4989             nan     0.1000    0.0001\n",
      "    40        0.4835             nan     0.1000   -0.0003\n",
      "    60        0.4736             nan     0.1000   -0.0003\n",
      "    80        0.4633             nan     0.1000   -0.0002\n",
      "   100        0.4562             nan     0.1000   -0.0002\n",
      "   120        0.4514             nan     0.1000   -0.0003\n",
      "   140        0.4476             nan     0.1000   -0.0003\n",
      "   150        0.4454             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5203             nan     0.1000    0.0014\n",
      "     2        0.5166             nan     0.1000    0.0010\n",
      "     3        0.5119             nan     0.1000    0.0017\n",
      "     4        0.5096             nan     0.1000    0.0003\n",
      "     5        0.5065             nan     0.1000    0.0007\n",
      "     6        0.5039             nan     0.1000   -0.0009\n",
      "     7        0.5014             nan     0.1000    0.0007\n",
      "     8        0.5003             nan     0.1000   -0.0001\n",
      "     9        0.4987             nan     0.1000   -0.0001\n",
      "    10        0.4972             nan     0.1000    0.0004\n",
      "    20        0.4820             nan     0.1000    0.0002\n",
      "    40        0.4584             nan     0.1000   -0.0002\n",
      "    60        0.4421             nan     0.1000   -0.0003\n",
      "    80        0.4298             nan     0.1000   -0.0005\n",
      "   100        0.4151             nan     0.1000   -0.0004\n",
      "   120        0.4040             nan     0.1000   -0.0003\n",
      "   140        0.3964             nan     0.1000   -0.0003\n",
      "   150        0.3925             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5182             nan     0.1000    0.0037\n",
      "     2        0.5124             nan     0.1000    0.0005\n",
      "     3        0.5060             nan     0.1000    0.0023\n",
      "     4        0.5022             nan     0.1000    0.0010\n",
      "     5        0.4987             nan     0.1000    0.0009\n",
      "     6        0.4957             nan     0.1000    0.0001\n",
      "     7        0.4940             nan     0.1000    0.0003\n",
      "     8        0.4922             nan     0.1000    0.0000\n",
      "     9        0.4884             nan     0.1000    0.0009\n",
      "    10        0.4854             nan     0.1000    0.0004\n",
      "    20        0.4657             nan     0.1000   -0.0001\n",
      "    40        0.4356             nan     0.1000    0.0001\n",
      "    60        0.4135             nan     0.1000   -0.0002\n",
      "    80        0.3957             nan     0.1000   -0.0002\n",
      "   100        0.3783             nan     0.1000   -0.0003\n",
      "   120        0.3645             nan     0.1000   -0.0004\n",
      "   140        0.3520             nan     0.1000   -0.0000\n",
      "   150        0.3438             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5232             nan     0.1000    0.0008\n",
      "     2        0.5218             nan     0.1000    0.0003\n",
      "     3        0.5206             nan     0.1000   -0.0000\n",
      "     4        0.5179             nan     0.1000    0.0011\n",
      "     5        0.5163             nan     0.1000    0.0008\n",
      "     6        0.5144             nan     0.1000    0.0005\n",
      "     7        0.5131             nan     0.1000    0.0001\n",
      "     8        0.5112             nan     0.1000    0.0005\n",
      "     9        0.5098             nan     0.1000    0.0004\n",
      "    10        0.5085             nan     0.1000    0.0004\n",
      "    20        0.4992             nan     0.1000   -0.0001\n",
      "    40        0.4834             nan     0.1000   -0.0001\n",
      "    60        0.4746             nan     0.1000   -0.0001\n",
      "    80        0.4668             nan     0.1000   -0.0000\n",
      "   100        0.4613             nan     0.1000   -0.0003\n",
      "   120        0.4552             nan     0.1000   -0.0003\n",
      "   140        0.4504             nan     0.1000   -0.0002\n",
      "   150        0.4486             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5213             nan     0.1000    0.0007\n",
      "     2        0.5168             nan     0.1000    0.0010\n",
      "     3        0.5123             nan     0.1000    0.0016\n",
      "     4        0.5098             nan     0.1000    0.0002\n",
      "     5        0.5079             nan     0.1000   -0.0000\n",
      "     6        0.5068             nan     0.1000   -0.0004\n",
      "     7        0.5045             nan     0.1000   -0.0000\n",
      "     8        0.5022             nan     0.1000    0.0003\n",
      "     9        0.5004             nan     0.1000    0.0001\n",
      "    10        0.4979             nan     0.1000    0.0003\n",
      "    20        0.4808             nan     0.1000    0.0002\n",
      "    40        0.4621             nan     0.1000   -0.0004\n",
      "    60        0.4480             nan     0.1000   -0.0002\n",
      "    80        0.4340             nan     0.1000   -0.0002\n",
      "   100        0.4206             nan     0.1000   -0.0004\n",
      "   120        0.4119             nan     0.1000   -0.0003\n",
      "   140        0.4034             nan     0.1000   -0.0004\n",
      "   150        0.4000             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5181             nan     0.1000    0.0020\n",
      "     2        0.5129             nan     0.1000    0.0013\n",
      "     3        0.5103             nan     0.1000    0.0003\n",
      "     4        0.5067             nan     0.1000    0.0009\n",
      "     5        0.5017             nan     0.1000    0.0009\n",
      "     6        0.4985             nan     0.1000    0.0006\n",
      "     7        0.4966             nan     0.1000    0.0000\n",
      "     8        0.4932             nan     0.1000    0.0006\n",
      "     9        0.4909             nan     0.1000   -0.0006\n",
      "    10        0.4878             nan     0.1000   -0.0002\n",
      "    20        0.4682             nan     0.1000   -0.0002\n",
      "    40        0.4368             nan     0.1000    0.0000\n",
      "    60        0.4138             nan     0.1000   -0.0004\n",
      "    80        0.3960             nan     0.1000   -0.0006\n",
      "   100        0.3813             nan     0.1000   -0.0002\n",
      "   120        0.3667             nan     0.1000   -0.0004\n",
      "   140        0.3541             nan     0.1000   -0.0005\n",
      "   150        0.3474             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5211             nan     0.1000    0.0007\n",
      "     2        0.5184             nan     0.1000    0.0004\n",
      "     3        0.5165             nan     0.1000    0.0005\n",
      "     4        0.5154             nan     0.1000    0.0002\n",
      "     5        0.5133             nan     0.1000    0.0007\n",
      "     6        0.5115             nan     0.1000    0.0006\n",
      "     7        0.5102             nan     0.1000   -0.0004\n",
      "     8        0.5093             nan     0.1000    0.0001\n",
      "     9        0.5082             nan     0.1000    0.0004\n",
      "    10        0.5074             nan     0.1000   -0.0003\n",
      "    20        0.4964             nan     0.1000    0.0003\n",
      "    40        0.4816             nan     0.1000   -0.0002\n",
      "    60        0.4726             nan     0.1000   -0.0003\n",
      "    80        0.4652             nan     0.1000   -0.0001\n",
      "   100        0.4587             nan     0.1000   -0.0001\n",
      "   120        0.4539             nan     0.1000    0.0000\n",
      "   140        0.4499             nan     0.1000   -0.0005\n",
      "   150        0.4491             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5206             nan     0.1000    0.0022\n",
      "     2        0.5152             nan     0.1000    0.0011\n",
      "     3        0.5127             nan     0.1000    0.0011\n",
      "     4        0.5104             nan     0.1000    0.0005\n",
      "     5        0.5070             nan     0.1000    0.0006\n",
      "     6        0.5055             nan     0.1000    0.0002\n",
      "     7        0.5029             nan     0.1000    0.0000\n",
      "     8        0.5008             nan     0.1000   -0.0000\n",
      "     9        0.4986             nan     0.1000   -0.0002\n",
      "    10        0.4973             nan     0.1000    0.0001\n",
      "    20        0.4805             nan     0.1000   -0.0002\n",
      "    40        0.4608             nan     0.1000    0.0001\n",
      "    60        0.4432             nan     0.1000   -0.0004\n",
      "    80        0.4290             nan     0.1000   -0.0002\n",
      "   100        0.4191             nan     0.1000   -0.0004\n",
      "   120        0.4084             nan     0.1000   -0.0001\n",
      "   140        0.3987             nan     0.1000   -0.0002\n",
      "   150        0.3956             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5180             nan     0.1000    0.0024\n",
      "     2        0.5136             nan     0.1000    0.0008\n",
      "     3        0.5101             nan     0.1000    0.0011\n",
      "     4        0.5077             nan     0.1000   -0.0000\n",
      "     5        0.5029             nan     0.1000    0.0014\n",
      "     6        0.5012             nan     0.1000   -0.0000\n",
      "     7        0.4983             nan     0.1000    0.0003\n",
      "     8        0.4944             nan     0.1000    0.0005\n",
      "     9        0.4927             nan     0.1000   -0.0001\n",
      "    10        0.4898             nan     0.1000    0.0002\n",
      "    20        0.4734             nan     0.1000    0.0002\n",
      "    40        0.4452             nan     0.1000   -0.0005\n",
      "    60        0.4270             nan     0.1000   -0.0001\n",
      "    80        0.4040             nan     0.1000   -0.0003\n",
      "   100        0.3878             nan     0.1000   -0.0003\n",
      "   120        0.3709             nan     0.1000   -0.0009\n",
      "   140        0.3573             nan     0.1000   -0.0005\n",
      "   150        0.3499             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        0.5193             nan     0.1000    0.0023\n",
      "     2        0.5144             nan     0.1000    0.0010\n",
      "     3        0.5095             nan     0.1000    0.0013\n",
      "     4        0.5058             nan     0.1000    0.0002\n",
      "     5        0.5023             nan     0.1000    0.0011\n",
      "     6        0.5000             nan     0.1000    0.0006\n",
      "     7        0.4978             nan     0.1000    0.0005\n",
      "     8        0.4957             nan     0.1000    0.0002\n",
      "     9        0.4931             nan     0.1000    0.0005\n",
      "    10        0.4913             nan     0.1000    0.0004\n",
      "    20        0.4746             nan     0.1000    0.0004\n",
      "    40        0.4531             nan     0.1000   -0.0003\n",
      "    60        0.4344             nan     0.1000    0.0000\n",
      "    80        0.4215             nan     0.1000   -0.0004\n",
      "   100        0.4066             nan     0.1000   -0.0004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objControl <- trainControl(method='cv', number=3, returnResamp='none', summaryFunction = twoClassSummary, classProbs = TRUE)\n",
    "gbm <- train(trainDF[,predictorsNames], trainDF[,outcomeName], \n",
    "                  method='gbm', \n",
    "                  trControl=objControl,  \n",
    "                  metric = \"ROC\",\n",
    "                  preProc = c(\"center\", \"scale\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   no  yes\n",
       "       no  4614  357\n",
       "       yes   18   11\n",
       "                                          \n",
       "               Accuracy : 0.925           \n",
       "                 95% CI : (0.9173, 0.9322)\n",
       "    No Information Rate : 0.9264          \n",
       "    P-Value [Acc > NIR] : 0.6601          \n",
       "                                          \n",
       "                  Kappa : 0.0451          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : <2e-16          \n",
       "                                          \n",
       "            Sensitivity : 0.99611         \n",
       "            Specificity : 0.02989         \n",
       "         Pos Pred Value : 0.92818         \n",
       "         Neg Pred Value : 0.37931         \n",
       "             Prevalence : 0.92640         \n",
       "         Detection Rate : 0.92280         \n",
       "   Detection Prevalence : 0.99420         \n",
       "      Balanced Accuracy : 0.51300         \n",
       "                                          \n",
       "       'Positive' Class : no              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_raw <- predict(object=gbm, testDF[,predictorsNames], type='raw')\n",
    "confusionMatrix(predictions_raw,testDF$churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = 0, case = 1\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the curve: 0.6983\n"
     ]
    }
   ],
   "source": [
    "predictions_prob <- predict(object=gbm, testDF[,predictorsNames], type='prob')\n",
    "auc <- roc(ifelse(testDF[,outcomeName]==\"yes\",1,0), predictions_prob[[2]])\n",
    "print(auc$auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -. glm and Stepwise regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = churn ~ ., family = binomial, data = trainDF)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.9539  -0.4131  -0.3070  -0.2118   3.3444  \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -1.338e+01  3.036e+02  -0.044 0.964837    \n",
       "cust_id      4.526e-07  9.921e-06   0.046 0.963618    \n",
       "Var7        -4.341e-05  6.659e-05  -0.652 0.514477    \n",
       "Var11        2.438e-04  1.292e-04   1.887 0.059174 .  \n",
       "Var13       -7.227e-05  1.112e-04  -0.650 0.515773    \n",
       "Var21       -7.240e-04  4.870e-04  -1.486 0.137151    \n",
       "Var24       -4.366e-05  1.674e-04  -0.261 0.794248    \n",
       "Var25       -3.094e-04  4.069e-04  -0.760 0.446977    \n",
       "Var28        1.024e-04  1.299e-04   0.788 0.430516    \n",
       "Var33        2.907e-06  1.123e-04   0.026 0.979348    \n",
       "Var35       -5.208e-05  4.022e-05  -1.295 0.195362    \n",
       "Var44        4.597e-05  6.450e-05   0.713 0.476043    \n",
       "Var45       -7.685e-05  1.203e-04  -0.639 0.522828    \n",
       "Var51        1.466e-05  2.754e-05   0.532 0.594434    \n",
       "Var57       -6.116e-02  2.851e-02  -2.145 0.031954 *  \n",
       "Var64       -1.251e-05  8.775e-05  -0.143 0.886642    \n",
       "Var65        4.950e-05  4.241e-05   1.167 0.243074    \n",
       "Var72        3.215e-05  7.855e-05   0.409 0.682347    \n",
       "Var73       -1.336e-02  3.437e-03  -3.887 0.000102 ***\n",
       "Var74        1.150e-04  4.142e-05   2.777 0.005480 ** \n",
       "Var76       -8.677e-05  2.389e-04  -0.363 0.716452    \n",
       "Var78       -7.253e-05  3.756e-05  -1.931 0.053500 .  \n",
       "Var83        6.270e-05  6.686e-05   0.938 0.348362    \n",
       "Var89       -8.888e-05  1.417e-04  -0.627 0.530496    \n",
       "Var91        7.058e-05  9.464e-05   0.746 0.455787    \n",
       "Var94       -1.886e-05  3.494e-05  -0.540 0.589386    \n",
       "Var98       -8.381e-05  1.296e-04  -0.647 0.517787    \n",
       "Var102      -1.351e-04  8.378e-05  -1.613 0.106846    \n",
       "Var105       3.610e-05  1.071e-04   0.337 0.736098    \n",
       "Var109      -3.201e-05  1.050e-04  -0.305 0.760488    \n",
       "Var112       2.534e-04  3.633e-04   0.698 0.485441    \n",
       "Var113       4.383e-07  8.704e-08   5.036 4.75e-07 ***\n",
       "Var118       1.313e-03  3.048e-02   0.043 0.965654    \n",
       "Var123      -5.634e-05  1.288e-04  -0.437 0.661807    \n",
       "Var125      -2.103e-04  1.505e-04  -1.397 0.162313    \n",
       "Var126       3.507e-04  5.647e-05   6.209 5.32e-10 ***\n",
       "Var128      -1.573e-04  1.311e-04  -1.200 0.230234    \n",
       "Var132       9.084e-05  5.153e-05   1.763 0.077892 .  \n",
       "Var134      -9.183e-05  3.032e-04  -0.303 0.761956    \n",
       "Var138       3.855e-04  1.520e-04   2.537 0.011188 *  \n",
       "Var140       2.108e-05  1.097e-04   0.192 0.847678    \n",
       "Var143      -1.318e-04  6.152e-05  -2.143 0.032126 *  \n",
       "Var144      -2.416e-04  8.906e-05  -2.712 0.006683 ** \n",
       "Var147       1.788e-04  1.162e-04   1.538 0.124059    \n",
       "Var149       6.289e-05  1.146e-04   0.549 0.583084    \n",
       "Var156       1.565e-04  1.471e-04   1.064 0.287435    \n",
       "Var160       9.472e-04  4.618e-04   2.051 0.040252 *  \n",
       "Var163      -4.143e-05  6.500e-05  -0.637 0.523912    \n",
       "Var165       1.901e-05  1.094e-04   0.174 0.862008    \n",
       "Var181      -7.358e-05  3.856e-05  -1.908 0.056334 .  \n",
       "Var189      -2.763e-05  2.141e-05  -1.291 0.196828    \n",
       "Var190      -1.414e-04  1.015e-04  -1.393 0.163759    \n",
       "Var192      -2.859e-04  3.447e-03  -0.083 0.933905    \n",
       "Var193      -3.299e-05  4.631e-05  -0.712 0.476247    \n",
       "Var194       2.935e-05  4.181e-05   0.702 0.482678    \n",
       "Var195       2.657e-05  4.112e-05   0.646 0.518231    \n",
       "Var196       1.545e-04  7.967e-05   1.939 0.052463 .  \n",
       "Var197       3.078e-04  1.749e-04   1.760 0.078431 .  \n",
       "Var199      -1.078e-03  1.333e-03  -0.809 0.418779    \n",
       "Var202       3.035e-02  1.342e-02   2.261 0.023766 *  \n",
       "Var203       8.800e-06  3.426e-05   0.257 0.797278    \n",
       "Var204      -5.149e-04  8.755e-04  -0.588 0.556461    \n",
       "Var205      -4.521e-05  2.582e-05  -1.751 0.079929 .  \n",
       "Var206      -1.284e-04  5.138e-05  -2.500 0.012436 *  \n",
       "Var208      -3.440e-05  3.453e-05  -0.996 0.319151    \n",
       "Var210      -1.267e-04  2.557e-05  -4.956 7.19e-07 ***\n",
       "Var211      -5.143e-06  3.106e-05  -0.166 0.868484    \n",
       "Var212       6.035e-05  4.590e-05   1.315 0.188569    \n",
       "Var216      -5.098e-04  1.985e-04  -2.568 0.010219 *  \n",
       "Var217      -1.364e-02  9.108e-03  -1.498 0.134182    \n",
       "Var218      -8.325e-04  2.547e-04  -3.269 0.001078 ** \n",
       "Var219       4.902e-05  2.462e-05   1.991 0.046466 *  \n",
       "Var221       1.268e-05  4.033e-05   0.314 0.753313    \n",
       "Var222       3.301e-04  4.368e-04   0.756 0.449769    \n",
       "Var223       3.850e-06  2.552e-05   0.151 0.880078    \n",
       "Var225      -1.154e-04  7.180e-05  -1.606 0.108171    \n",
       "Var226      -2.995e-05  1.558e-04  -0.192 0.847536    \n",
       "Var228       5.937e-05  5.026e-05   1.181 0.237449    \n",
       "Var229       8.761e-06  5.229e-05   0.168 0.866942    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2628.5  on 4999  degrees of freedom\n",
       "Residual deviance: 2326.5  on 4921  degrees of freedom\n",
       "AIC: 2484.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 14\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# full log model\n",
    "full.model <- glm(churn ~., data = trainDF, family = binomial)\n",
    "summary(full.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "probabilities <- full.model %>% predict(testDF, type = \"response\")\n",
    "predicted.classes <- ifelse(probabilities > 0.5, \"pos\", \"neg\")\n",
    "# Prediction accuracy\n",
    "observed.classes <- testDF$churn\n",
    "mean(predicted.classes == observed.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stepwise model\n",
    "step.model <- full.model %>% stepAIC(trace = FALSE)\n",
    "summary(step.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "probabilities <- predict(step.model, testDF, type = \"response\")\n",
    "predicted.classes <- ifelse(probabilities > 0.5, \"pos\", \"neg\")\n",
    "# Prediction accuracy\n",
    "observed.classes <- testDF$churn\n",
    "mean(predicted.classes == observed.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = table(observed.classes, predicted.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
